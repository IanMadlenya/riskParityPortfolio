---
title: "Fast Design of Risk Parity Portfolios"
author:
- name: "Zé Vinícius and Daniel P. Palomar"
  affiliation: "Hong Kong University of Science and Technology (HKUST)"
date: "`r Sys.Date()`"
output:
  bookdown::html_document2:
    base_format: prettydoc::html_pretty
    theme: cayman
    highlight: vignette
    fig_caption: yes
    number_sections: no
    toc: yes
    toc_depth: 1
  bookdown::pdf_document2:
    fig_caption: yes
    number_sections: yes
    toc: yes
    toc_depth: 2
header-includes:
  \allowdisplaybreaks
indent: yes
csl: ieee.csl
bibliography: refs.bib
vignette: >
  %\VignetteIndexEntry{Design of Risk Parity Portfolios}
  %\VignetteKeyword{portfolio, risk-parity, risk, optimization}
  %\VignetteEncoding{UTF-8}
  %\VignetteEngine{knitr::rmarkdown}
---

```{r, echo = FALSE}
library(knitr)
opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  fig.align = "center",
  fig.retina = 2,
  out.width = "75%",
  dpi = 96
)
knit_hooks$set(pngquant = hook_pngquant)
#Help on bookdown: https://bookdown.org/yihui/bookdown/
#rmarkdown::render("vignettes/RiskParityPortfolio-vignette.Rmd", "all")
#rmarkdown::render("vignettes/RiskParityPortfolio-vignette.Rmd", "bookdown::html_document2")
#rmarkdown::render("vignettes/RiskParityPortfolio-vignette.Rmd", "bookdown::pdf_document2")
#tools::compactPDF("vignettes/RiskParityPortfolio-vignette.pdf", gs_quality = "ebook")
```

-----------
This vignette illustrates the design of risk-parity portfolios, widely
used by practitioners in the financial industry, with the package
`riskParityPortfolio`, gives a description of the algorithms used, and
compares the performance against existing packages such as `cccp` and `FinCovRegularization`.

# Vanilla risk parity portfolio

A risk parirty portfolio denotes a class of portfolios whose assets verify the following equalities:
$$\begin{equation}
w_i \dfrac{\partial f(\mathbf{w})}{\partial w_i} = w_j \dfrac{\partial f(\mathbf{w})}{\partial w_j}, \forall i, j,
\end{equation}
$$
where $f$ is a positively homogeneous function of degree one that measures the total risk of the portfolio.
In other words, the marginal risk contributions for every asset in a risk parity portfolio are equal.
A common choice for $f$, for instance, is the standard deviation of the portfolio,
which is usually called volatility, i.e., $f(\mathbf{w}) = \sqrt{\mathbf{w}^{T}\Sigma\mathbf{w}}$.

With that particular choice of $f$, the risk parity requirements become
$$
\begin{equation}
w_i(\Sigma \mathbf{w})_{i} = w_j(\Sigma \mathbf{w})_{j}, \forall i, j.
\end{equation}
$$

A natural extension of the risk parity portfolio is the so called risk budget portfolio, in which
the marginal risk contributions match preassigned quantities. Mathematically,
$$
\begin{equation}
(\Sigma \mathbf{w})_i w_i = b_i \mathbf{w}^{T}\Sigma\mathbf{w}, \forall i,
\end{equation}
$$
where $\mathbf{b} \triangleq (b_1, b_2, ..., b_N)$ is the vector of desired
marginal risk contributions.

With the goal of designing risk budget portfolios, Spinu proposed in [@Spinu2013] to solve the
following convex optimization problem:
$$\begin{array}{ll}
\underset{\mathbf{w}}{\textsf{minimize}} & \frac{1}{2}\mathbf{w}^{T}\Sigma\mathbf{w} - \sum_{i=1}^{N}b_i\log(w_i)\\
\textsf{subject to} & \mathbf{1}^T\mathbf{w}=1\\
 & \mathbf{w}\ge\mathbf{0}.
\end{array}$$

It turns out, as shown in [@Spinu2013], that the unique solution for the optimization problem
stated above attains the risk budget requirements in an exact fashion. Such solution can be
computed using convex optimization packages, such as CVXR, but a faster implementation of a
Newton algorithm, also proposed by [@Spinu2013], is implemented in this package.

Let's see a comparison, in terms of computational time, of our Newton implementation
against the `rp()` function from the `cccp` package. For a fair comparison, we
implement the core algorithm in `risk_parity_portfolio_nn()`, which only computes the
risk parity weights, just like `rp()`. However, users are advised to use the function
`riskParityPortfolioNewton()`, which contains more information such as objective function
value and the individual risk contributions associated with each asset.

```{r}
library(microbenchmark)
library(cccp)
library(riskParityPortfolio)

N <- 100
V <- matrix(rnorm(N^2), nrow = N)
Sigma <- V %*% t(V)
b <- rep(1/N, N)

# use risk_parity_portfolio_nn with default values of tolerance and number of iterations
op <- microbenchmark(rp_cccp = rp(b, Sigma, b, optctrl = ctrl(trace = FALSE)),
                     newton = risk_parity_portfolio_nn(Sigma, b, 1e-6, 50),
                     times = 10L)
print(op)
par(mar = c(7, 4, 4, 2))
boxplot(op, ylab = "Time in Milliseconds", xlab = NULL, unit = "ms", outline = FALSE, las = 2)
```

As it can be observed, our implementation is quite faster (a factor of ~3x) than the interior-point method
used by `cccp`. We suggest the interested reader to check out chapter 11 of reference [@BoydCVXBook]
for a thorough explanation on interior-point methods.

# Modern risk parity portfolio
The design of risk parity portfolios as solved by [@Spinu2013] is of paramount importance
both for academia and industry. However, practitioners would like the ability to include
additional constraints and objective terms desired in practice, such as the mean return, box constraints, etc.,
that often give rise to non-convex formulations.

Towards the design of risk parity portfolios with more practical applicability,
this package provides two functions: `riskParityPortfolioSCA()` and
`riskParityPortfolioGenSolver()`. The first one makes use of the successive convex approximation (SCA)
framework in order to optimize the portfolio weights, which is based on the works of Feng & Palomar
[@FengPal2016monograph][@FengPal2015riskparity], whereas `riskParityPortfolioGenSolver()` uses general
solvers widely used by the R community such as `slsqp` and `alabama`.

A simple example on how to use those functions is as follows:
```{r, message = FALSE}
library(riskParityPortfolio)
library(PerformanceAnalytics)

# generate synthetic data
set.seed(123)
N <- 10
V <- matrix(rnorm(N^2), nrow = N)
Sigma <- V %*% t(V)

# uniform initial guess for the portfolio weights
w0 <- rep(1/N, N)

# compute risk parity portfolios using different methods
sca <- riskParityPortfolioSCA(Sigma, w0 = w0)
slsqp <- riskParityPortfolioGenSolver(Sigma, w0 = w0, method = "slsqp")
alabama <- riskParityPortfolioGenSolver(Sigma, w0 = w0, method = "alabama")
newton <- riskParityPortfolioNewton(Sigma)

# plot the portfolio designed by each method
barplot(rbind(sca$w, slsqp$w, alabama$w, newton$w),
        main = "Portfolio Weights", xlab = "stocks", ylab = "dollars",
        beside = TRUE, col = rainbow8equal[1:4], legend = c("sca", "slsqp", "alabama", "newton"))
# plot the risk contribution associated with each portfolio
barplot(rbind(sca$risk_contribution, slsqp$risk_contribution, alabama$risk_contribution, newton$risk_contribution),
        main = "Risk Contribution of the Portfolios", xlab = "stocks", ylab = "dollars",
        beside = TRUE, col = rainbow8equal[1:4], legend = c("sca", "slsqp", "alabama", "newton"))
```
As presented earlier, the risk parity portfolios are designed in
such a way as to ensure equal risk contribution from the assests, which can be noted in the chart above.

Many more parameters are available in both `riskParityPortfolioSCA()` and `riskParityPortfolioGenSolver()`,
please check the documentation for their full description.

Now, let's explore the effects of having the mean return in the optimization problem.
We recall that the optimization problem that include the mean return can be expressed as
$$\begin{array}{ll}
\underset{\mathbf{w}}{\textsf{minimize}} &
R(\mathbf{w}) - \lambda \mathbf{w}^{T}\boldsymbol{\mu}\\
\textsf{subject to} & \mathbf{1}^T\mathbf{w}=1.
\end{array}$$

```{r, message=FALSE}
library(scales)
library(latex2exp)

N <- 100
V <- matrix(rnorm(N ^ 2), nrow = N)
Sigma <- V %*% t(V)
mu <- runif(N)
w0 <- riskParityPortfolioNewton(Sigma)$w  # vanilla solution as starting point

lmd_sweep <- c(0, 10 ^ (seq(-5, 2, .25)))
mean_return_sca <- c()
risk_parity_sca <- c()
mean_return_gen <- c()
risk_parity_gen <- c()

for (lmd in lmd_sweep) {
  rpp_sca <- riskParityPortfolioSCA(Sigma, w0 = w0, mu = mu, lambda = lmd)
  rpp_gen <- riskParityPortfolioGenSolver(Sigma, w0 = w0, mu = mu, lambda = lmd)
  mean_return_sca <- c(mean_return_sca, rpp_sca$mean_return)
  risk_parity_sca <- c(risk_parity_sca, rpp_sca$risk)
  mean_return_gen <- c(mean_return_gen, rpp_gen$mean_return)
  risk_parity_gen <- c(risk_parity_gen, rpp_gen$risk)
}

colors <- c(alpha("blue", .5), alpha("red", .5))
plot(risk_parity_sca, mean_return_sca, type = "b", pch=19, cex=.6, col=colors[1],
     xlab = "Risk", ylab = "Expected Return",
     ylim = c(min(mean_return_sca, mean_return_gen), max(mean_return_sca, mean_return_gen)),
     xlim = c(min(risk_parity_sca, risk_parity_gen), max(risk_parity_sca, risk_parity_gen)),
     main = "Expected Return vs Risk for SCA and General Solver algorithms")
lines(risk_parity_gen, mean_return_gen, type = "b", pch=19, cex=.6, col=colors[2])
points(risk_parity_sca[1], mean_return_sca[1], pch=24)
points(risk_parity_gen[1], mean_return_gen[1], pch=25)
legend("bottomright", legend=c("SCA", "GenSolver", TeX("SCA w/ $\\lambda = 0$"), TeX("GenSolver w/ $\\lambda = 0$")),
       col=c(colors, "black", "black"), pch = c(19, 19, 24, 25))
```

It can be noted that both algorithms give almost the same results.
Additionally, note that we have initialized them with the solution
given by `riskParityPortfolioNewton()`, since it gives the exact and unique
solution when $\lambda = 0$.


# Comparison with other packages
Others R packages with the goal of designing risk parity portfolios do exist,
such as `FinCovRegularization` and `cccp`. Let's check how do they perform
against `riskParityPortfolio`.

```{r, message = FALSE}
library(FinCovRegularization)
library(cccp)

# generate synthetic data
set.seed(123)
N <- 10
V <- matrix(rnorm(N ^ 2), nrow = N)
Sigma <- V %*% t(V)

# uniform initial guess for the portfolio weights
w0 <- rep(1/N, N)

# compute risk parity portfolios using different methods
sca <- riskParityPortfolioSCA(Sigma, w0 = w0)
slsqp <- riskParityPortfolioGenSolver(Sigma, w0 = w0, method = "slsqp")
alabama <- riskParityPortfolioGenSolver(Sigma, w0 = w0, method = "alabama")
newton <- riskParityPortfolioNewton(Sigma)

fincov_w <- RiskParity(Sigma)
fincov_risk_contribution <- c(fincov_w * (Sigma %*% fincov_w))
# The list of arguments is the following: 1) the initial guess for the portfolio weights,
# 2) the covariance matrix of the asset returns, 3) the marginal risk contributions
cccp_w <- c(getx(rp(w0, Sigma, mrc = w0, optctrl = ctrl(trace = FALSE))))
cccp_risk_contribution <- c(cccp_w * (Sigma %*% cccp_w))

barplot(rbind(sca$w, slsqp$w, alabama$w, newton$w, fincov_w, cccp_w),
        main = "Portfolios Weights", xlab = "stocks", ylab = "dollars",
        beside = TRUE, col = rainbow8equal[1:6],
        legend = c("sca", "slsqp", "alabama", "newton", "fincov", "cccp"))
barplot(rbind(sca$risk_contribution, slsqp$risk_contribution, alabama$risk_contribution,
              newton$risk_contribution, fincov_risk_contribution, cccp_risk_contribution),
        main = "Risk Contribution of the Portfolios", xlab = "stocks", ylab = "dollars",
        beside = TRUE, col = rainbow8equal[1:6],
        legend = c("sca", "slsqp", "alabama", "newton", "fincov", "cccp"))
```

Apart from the `RiskParity` function from the `FinCovRegularization` package,
all the other functions perform the same. `FinCovRegularization` uses a general
solver with a hard coded initial guess for the portfolio weights. We conjecture
that its poor initialization might be the reason for the convergence to a local solution.

# Formulations
In general, with different constraints and objective functions, exact parity cannot be achieved and one needs to define a risk term to be
minimized: $R(\mathbf{w}) = \sum_{i=1}^{N}\left(g_{i}\left(\mathbf{w}\right)\right)^{2}$, where the $g_{i}$'s denote the different risk contribution errors, e.g., $g_{i} = w_{i}\left(\boldsymbol{\Sigma}\mathbf{w}\right)_i - b_i\mathbf{w}^T\boldsymbol{\Sigma}\mathbf{w}$.
A double-index summation can also be used:
$R(\mathbf{w}) = \sum_{i,j=1}^{N}\left(g_{ij}\left(\mathbf{w}\right)\right)^{2}$.

We condiser the risk formulations as presented in [@FengPal2015riskparity].
They can be passed through the keyword argument `formulation` in the functions
`riskParityPortfolioSCA()` and `riskParityPortfolioGenSolver()`.

The name of the formulations and their mathematical expressions are presented as follows.

**Formulation "rc-double-index"**:
$$R(\mathbf{w}) = \sum_{i,j=1}^{N}\left(w_{i}\left(\boldsymbol{\Sigma}\mathbf{w}\right)_{i}-w_{j}\left(\boldsymbol{\Sigma}\mathbf{w    }\right)_{j}\right)^{2}
$$

**Formulation "rc-vs-theta"**:
$$
R(\mathbf{w},\theta) = \sum_{i=1}^{N}\left(w_{i}\left(\boldsymbol{\Sigma}\mathbf{w}\right)_i - \theta \right)^{2}
$$

**Formulation "rc-over-var-vs-b"**:
$$
R(\mathbf{w}) = \sum_{i=1}^{N}\left(\frac{w_{i}\left(\boldsymbol{\Sigma}\mathbf{w}\right)_i}{\mathbf{w}^T\boldsymbol{\Sigma}\mathbf{w}}-b_i\right)^{2}
$$

**Formulation "rc-over-b double-index"**:
$$
R(\mathbf{w}) = \sum_{i,j=1}^{N}\left(\frac{w_i\left(\boldsymbol{\Sigma}\mathbf{w}\right)_i}{b_i} - \frac{w_j\left(\boldsymbol{\Sigma}\mathbf{w}\right)_j}{b_j}\right)^{2}
$$

**Formulation "rc-vs-b-times-var"**:
$$
R(\mathbf{w}) = \sum_{i=1}^{N}\left(w_{i}\left(\boldsymbol{\Sigma}\mathbf{w}\right)_i - b_i\mathbf{w}^T\boldsymbol{\Sigma}\mathbf{w}\right)^{2}
$$

**Formulation "rc-over-sd vs b-times-sd"**:
$$
R(\mathbf{w}) = \sum_{i=1}^{N}\left(\frac{w_{i}\left(\boldsymbol{\Sigma}\mathbf{w}\right)_i}{\sqrt{\mathbf{w}^T\boldsymbol{\Sigma}\mathbf{w}}}-b_i\sqrt{\mathbf{w}^T\boldsymbol{\Sigma}\mathbf{w}}\right)^{2}
$$

**Formulation "rc-over-b vs theta"**:
$$
R(\mathbf{w},\theta) = \sum_{i=1}^{N}\left(\frac{w_{i}\left(\boldsymbol{\Sigma}\mathbf{w}\right)_i}{b_i} - \theta \right)^{2}
$$

**Formulation "rc-over-var"**:
$$
R(\mathbf{w}) = \sum_{i=1}^{N}\left(\frac{w_{i}\left(\boldsymbol{\Sigma}\mathbf{w}\right)_i}{\mathbf{w}^T\boldsymbol{\Sigma}\mathbf{w}}\right)^{2}
$$

In the subsections that follows we explore the computational time required by
`riskParityPortfolioGenSolver()` and `riskParityPortfolioSCA()` for some of the formulations presented above.
Additionally, we compare `riskParityPortfolioGenSolver()` without using the gradient of the objective function.

## Experiment: formulation "rc-over-var vs b"
```{r}
set.seed(123)
N <- 100
V <- matrix(rnorm(N^2), nrow = N)
Sigma <- V %*% t(V)

res_slsqp <- riskParityPortfolioGenSolver(Sigma, 
                                          formulation = "rc-over-var vs b",
                                          method = "slsqp")
res_slsqp_nograd <- riskParityPortfolioGenSolver(Sigma,
                                                 formulation = "rc-over-var vs b",
                                                 method = "slsqp",
                                                 use_gradient = FALSE)
res_alabama <- riskParityPortfolioGenSolver(Sigma,
                                            formulation = "rc-over-var vs b",
                                            method = "alabama")
res_alabama_nograd <- riskParityPortfolioGenSolver(Sigma,
                                                   formulation = "rc-over-var vs b",
                                                   method = "alabama",
                                                   use_gradient = FALSE)
res_sca <- riskParityPortfolioSCA(Sigma, formulation = "rc-over-var vs b")

plot(res_slsqp_nograd$elapsed_time, res_slsqp_nograd$obj_fun, type = "b",
     pch=19, cex=.6, col = "blue", xlab = "Elapsed time (seconds)",
     ylab = "Objective function", main = "Convergence trend versus CPU time",
     ylim = c(0, 0.01))
lines(res_alabama$elapsed_time, res_alabama$obj_fun, type = "b", pch=18, cex=.8,
      col = "red")
lines(res_alabama_nograd$elapsed_time, res_alabama_nograd$obj_fun, type = "b", pch=17,
      cex=.8, col = "purple")
lines(res_slsqp$elapsed_time, res_slsqp$obj_fun, type = "b", pch=16, cex=.8,
      col = "green")
lines(res_sca$elapsed_time, res_sca$obj_fun, type = "b", pch=15, cex=.8,
      col = "black")

legend("topright", legend=c("alabama-solver-nograd",
                            "alabama-solver",
                            "slsqp-solver-nograd",
                            "slsqp-solver",
                            "sca"),
       col=c("purple", "red", "blue", "green", "black"), lty=c(1, 1, 1), cex=0.8)
```

## Experiment: formulation "rc vs b-times-var"
```{r}
res_slsqp <- riskParityPortfolioGenSolver(Sigma,
                                          formulation = "rc vs b-times-var",
                                          method = "slsqp")
res_slsqp_nograd <- riskParityPortfolioGenSolver(Sigma,
                                                 formulation = "rc vs b-times-var",
                                                 method = "slsqp",
                                                 use_gradient = FALSE)
res_alabama <- riskParityPortfolioGenSolver(Sigma,
                                            formulation = "rc vs b-times-var",
                                            method = "alabama")
res_alabama_nograd <- riskParityPortfolioGenSolver(Sigma,
                                                   formulation = "rc vs b-times-var",
                                                   method = "alabama",
                                                   use_gradient = FALSE)
res_sca <- riskParityPortfolioSCA(Sigma, formulation = "rc vs b-times-var")

plot(res_slsqp_nograd$elapsed_time, res_slsqp_nograd$obj_fun, type = "b",
     pch=19, cex=.6, col = "blue", xlab = "Elapsed time (seconds)",
     ylab = "Objective function", main = "Convergence trend versus CPU time",
     ylim = c(0, 0.009))
lines(res_alabama$elapsed_time, res_alabama$obj_fun, type = "b", pch=18, cex=.8,
      col = "red")
lines(res_alabama_nograd$elapsed_time, res_alabama_nograd$obj_fun, type = "b", pch=17,
      cex=.8, col = "purple")
lines(res_slsqp$elapsed_time, res_slsqp$obj_fun, type = "b", pch=16, cex=.8,
      col = "green")
lines(res_sca$elapsed_time, res_sca$obj_fun, type = "b", pch=15, cex=.8,
      col = "black")

legend("topright", legend=c("alabama-solver-nograd",
                            "alabama-solver",
                            "slsqp-solver-nograd",
                            "slsqp-solver",
                            "sca"),
       col=c("purple", "red", "blue", "green", "black"), lty=c(1, 1, 1), cex=0.8)
```

## Experiment: formulation "rc-over-sd vs b-times-sd"
```{r}
res_slsqp <- riskParityPortfolioGenSolver(Sigma,
                                          formulation = "rc-over-sd vs b-times-sd",
                                          method = "slsqp")
res_slsqp_nograd <- riskParityPortfolioGenSolver(Sigma,
                                                 formulation = "rc-over-sd vs b-times-sd",
                                                 method = "slsqp",
                                                 use_gradient = FALSE)
res_alabama <- riskParityPortfolioGenSolver(Sigma,
                                            formulation = "rc-over-sd vs b-times-sd",
                                            method = "alabama")
res_alabama_nograd <- riskParityPortfolioGenSolver(Sigma,
                                                   formulation = "rc-over-sd vs b-times-sd",
                                                   method = "alabama",
                                                   use_gradient = FALSE)
res_sca <- riskParityPortfolioSCA(Sigma, formulation = "rc-over-sd vs b-times-sd")

plot(res_slsqp_nograd$elapsed_time, res_slsqp_nograd$obj_fun, type = "b",
     pch=19, cex=.6, col = "blue", xlab = "Elapsed time (seconds)",
     ylab = "Objective function", main = "Convergence trend versus CPU time",
     ylim = c(0, 0.01))
lines(res_alabama$elapsed_time, res_alabama$obj_fun, type = "b", pch=18, cex=.8,
      col = "red")
lines(res_alabama_nograd$elapsed_time, res_alabama_nograd$obj_fun, type = "b", pch=17,
      cex=.8, col = "purple")
lines(res_slsqp$elapsed_time, res_slsqp$obj_fun, type = "b", pch=16, cex=.8,
      col = "green")
lines(res_sca$elapsed_time, res_sca$obj_fun, type = "b", pch=15, cex=.8,
      col = "black")

legend("topright", legend=c("alabama-solver-nograd",
                            "alabama-solver",
                            "slsqp-solver-nograd",
                            "slsqp-solver",
                            "sca"),
       col=c("purple", "red", "blue", "green", "black"), lty=c(1, 1, 1), cex=0.8)
```

## Experiment with real market data
```{r}
library(sparseIndexTracking)
library(xts)
data(INDEX_2010)
Sigma <- cov(INDEX_2010$X)

res_slsqp <- riskParityPortfolioGenSolver(Sigma,
                                          formulation = "rc-over-var vs b",
                                          method = "slsqp")
res_slsqp_nograd <- riskParityPortfolioGenSolver(Sigma,
                                                 formulation = "rc-over-var vs b",
                                                 method = "slsqp",
                                                 use_gradient = FALSE)
res_alabama <- riskParityPortfolioGenSolver(Sigma,
                                            formulation = "rc-over-var vs b",
                                            method = "alabama")
res_alabama_nograd <- riskParityPortfolioGenSolver(Sigma,
                                                   formulation = "rc-over-var vs b",
                                                   method = "alabama",
                                                   use_gradient = FALSE)
res_sca <- riskParityPortfolioSCA(Sigma, formulation = "rc-over-var vs b")

plot(res_alabama_nograd$elapsed_time, res_alabama_nograd$obj_fun, type = "b",
     pch=19, cex=.6, col = "purple", xlab = "Elapsed time (seconds)",
     ylab = "Objective function", main = "Convergence trend versus CPU time")
lines(res_alabama$elapsed_time, res_alabama$obj_fun, type = "b", pch=18, cex=.8,
      col = "red")
lines(res_slsqp_nograd$elapsed_time, res_slsqp_nograd$obj_fun, type = "b", pch=17,
      cex=.8, col = "blue")
lines(res_slsqp$elapsed_time, res_slsqp$obj_fun, type = "b", pch=16, cex=.8,
      col = "green")
lines(res_sca$elapsed_time, res_sca$obj_fun, type = "b", pch=15, cex=.8,
      col = "black")

legend("topright", legend=c("alabama-solver-nograd",
                            "alabama-solver",
                            "slsqp-solver-nograd",
                            "slsqp-solver",
                            "sca"),
       col=c("purple", "red", "blue", "green", "black"), lty=c(1, 1, 1), cex=0.8)
```

It can be noted that the general solvers greatly benefit from the additional gradient
information. Despite that fact, the SCA method still performs faster. Additionally,
in some cases, the SCA method attains a better solution than the other methods.

# Conclusions
This package provides fast implementations for both vanilla risk parity and more
general usually non-convex formulations. From the experiments performed in this vignette,
we advise users to use `riskParityPortfolioNewton()` for the former case
and `riskParityPortfolioSCA()` for the latter.

# References {-}
\setlength{\parindent}{-0.2in}
\setlength{\leftskip}{0.2in}
\setlength{\parskip}{8pt}
\noindent
