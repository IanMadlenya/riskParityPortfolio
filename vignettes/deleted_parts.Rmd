**This derivation is in the making:**
  
  Observations:
  
  1. each terms $\nabla g_{ij} = (\mathbf{M}_i + \mathbf{M}_i^T + \mathbf{M}_j + \mathbf{M}_j^T)\mathbf{w}$ is symmetric, i.e., $\nabla g_{ij} = \nabla g_{ji}$
    2. we need $\mathbf{A}$ only through the terms $\mathbf{A}^T\mathbf{A}$ (which are symmetric) and $\mathbf{A}^T\mathbf{g}$, which can simplify things a lot
  
  
  
  and 
  $$\nabla g_{ij} = \left[\textsf{Diag}(\boldsymbol{\Sigma}\mathbf{w}) + \boldsymbol{\Sigma}\textsf{Diag}(\mathbf{w})\right]_{:,i} + \left[\textsf{Diag}(\boldsymbol{\Sigma}\mathbf{w}) + \boldsymbol{\Sigma}\textsf{Diag}(\mathbf{w})\right]_{:,j}$$
    $$[\nabla g_{ij}]_k = \delta_{ki}(\boldsymbol{\Sigma}\mathbf{w})_i + \boldsymbol{\Sigma}_{k,i}w_i + \delta_{kj}(\boldsymbol{\Sigma}\mathbf{w})_j + \boldsymbol{\Sigma}_{k,j}w_j$$
    
    4. TBD:
    $$[\mathbf{A}^T\mathbf{A}]_{kl} = \sum_{i,j} [\nabla g_{ij}]_k[\nabla g_{ij}]_l$$
    Consider one of the cross terms after the multiplication:
    $$\sum_{i,j} \boldsymbol{\Sigma}_{k,i}w_i \cdot \boldsymbol{\Sigma}_{l,j}w_j = $$
    
    
    
**My old derivation [this one is correct, I fixed it]**:
Matrix $\mathbf{A}=\left[\nabla g_1,\dots,\nabla g_N\right]^T$ is more involved to compute (we will avoid the M-notation as it gets too involved). The partial derivative is
$$\frac{\partial g_i}{\partial r_j} = \frac{\delta_{ij}}{\mathbf{1}^T\mathbf{r}} - \frac{r_i}{(\mathbf{1}^T\mathbf{r})^2}$$
and the gradient is 
$$\nabla_\mathbf{x} g_i = \frac{1}{\mathbf{1}^T\mathbf{r}}\left(\mathbf{e}_i-\frac{r_i\mathbf{1}}{\mathbf{1}^T\mathbf{r}}\right)$$
where $\mathbf{e}_i$ is the $i$-canonical vector (all-zero except a 1 at the $i$-th position). We can then write the Jacobian as
$$\textsf{J}_{\mathbf{x}}\mathbf{g} = \frac{1}{\mathbf{1}^T\mathbf{r}}\left(\mathbf{I}-\frac{\mathbf{r}\otimes \mathbf{1}^T}{\mathbf{1}^T\mathbf{r}}\right),$$ where $\otimes$ denotes Kronecker product.
Finally we can use the Jacobian chain rule (recall that $\textsf{J}_{\mathbf{w}}\mathbf{x} = \textsf{Diag}(\mathbf{w})\boldsymbol{\Sigma} + \textsf{Diag}(\boldsymbol{\Sigma}\mathbf{w})$):
$$\mathbf{A} \triangleq \textsf{J}_{\mathbf{w}}\mathbf{g} = \frac{1}{\mathbf{1}^T\mathbf{r}}\left(\mathbf{I}-\frac{\mathbf{r}\otimes \mathbf{1}^T}{\mathbf{1}^T\mathbf{r}}\right) \cdot \left(\textsf{Diag}(\mathbf{w})\boldsymbol{\Sigma} + \textsf{Diag}(\boldsymbol{\Sigma}\mathbf{w})\right),$$
which can be more efficiently expressed as
$$\mathbf{A} = \frac{1}{\mathbf{1}^T\mathbf{r}}\left(\left(\textsf{Diag}(\mathbf{w})\boldsymbol{\Sigma} + \textsf{Diag}(\boldsymbol{\Sigma}\mathbf{w})\right)-\frac{1}{\mathbf{1}^T\mathbf{r}}\mathbf{r}\otimes\left(\mathbf{1}^T\left(\textsf{Diag}(\mathbf{w})\boldsymbol{\Sigma} + \textsf{Diag}(\boldsymbol{\Sigma}\mathbf{w})\right)\right)\right).$$
This can be efficiently coded as
```{r, eval=FALSE}
sum_r <- sum(r)
Ut <- diag(Sigma_w) + Sigma*w
v <- colSums(Ut)
A <- Ut/sum_r - 1/(sum_r^2) * r %o% v
```
    
    

**[This is wrong!!!] My old derivation (only for $b_i=1/N$)**:  
Its derivative w.r.t. $r_j$ can be expressed as
$$
\begin{equation}
\dfrac{\partial g_{i}(\mathbf{w})}{\partial r_j} = \dfrac{\delta_{ij}}{\sqrt{\mathbf{1}^{T}\mathbf{r}}} -
\dfrac{r_i}{2 (\mathbf{1}^{T}\mathbf{r})^{3/2}} - \dfrac{1}{2N\sqrt{\mathbf{1}^{T}\mathbf{r}}}.
\end{equation}
$$

Hence, its gradient with respect to $\mathbf{r}$ is
$$
\begin{equation}
\nabla_{\mathbf{r}}g_{i}(\mathbf{w}) = \dfrac{1}{{\sqrt{\mathbf{1}^{T}\mathbf{r}}}} \left(\mathbf{e}_{i}
- \dfrac{\mathbf{1}}{2N} - \dfrac{\mathbf{r}}{2 \mathbf{1}^{T}\mathbf{r}}\right).
\end{equation}
$$

Its Jacobian can then be written as
$$
\begin{equation}
\textsf{J}_{\mathbf{r}}\mathbf{g} = \dfrac{1}{{\sqrt{\mathbf{1}^{T}\mathbf{r}}}} \left(\mathbf{I}
- \dfrac{\mathbf{1}\mathbf{1}^{T}}{2N} - \dfrac{\mathbf{1}\otimes\mathbf{r}^{T}}{2 \mathbf{1}^{T}\mathbf{r}}\right).
\end{equation}
$$

Finally, the matrix $\mathbf{A} \triangleq \textsf{J}_\mathbf{w}\mathbf{g}$ can be written as
$$
\begin{align}
\mathbf{A} = \left(\textsf{Diag}(\mathbf{w})\boldsymbol{\Sigma} +
\textsf{Diag}(\boldsymbol{\Sigma}\mathbf{w})\right) \cdot \dfrac{1}{{\sqrt{\mathbf{1}^{T}\mathbf{r}}}} \left(\mathbf{I} - \dfrac{\mathbf{1}\mathbf{1}^{T}}{2N} - \dfrac{\mathbf{1}\otimes\mathbf{r}^{T}}{2 \mathbf{1}^{T}\mathbf{r}}\right)
\end{align}
$$